{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Module & Utility Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Utilities.EvaluationMain import *\n",
    "from Utilities.Utilities import ReadYaml, SerializeObjects, DeserializeObjects, LoadModelConfigs, LoadParams\n",
    "from Models.Caller64 import *\n",
    "from Utilities.Visualization import VisReconGivenZ_FCA, HeatMapFreqZ_FCA, VisReconGivenFC_ZA, VisReconExtractZ_FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Configurations and Evaluation Tables (Accuracy & MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_tables(directory, acc_keyword, acc_pattern, mi_keyword, mi_pattern):\n",
    "    \"\"\"\n",
    "    Load and combine evaluation tables from a specified directory based on filtering keywords.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing CSV table files.\n",
    "        acc_keyword (str): Keyword to identify accuracy tables.\n",
    "        acc_pattern (str): Additional substring that accuracy table filenames must contain.\n",
    "        mi_keyword (str): Keyword to identify MI (Mutual Information) tables.\n",
    "        mi_pattern (str): Additional substring that MI table filenames must contain.\n",
    "\n",
    "    Returns:\n",
    "        acc_df (DataFrame): A concatenated DataFrame of accuracy tables with an added 'RMSE' column.\n",
    "        mi_df (DataFrame): A concatenated DataFrame of MI tables.\n",
    "    \"\"\"\n",
    "    # List all files in the specified directory\n",
    "    table_list = os.listdir(directory)\n",
    "    \n",
    "    # Load and combine accuracy tables\n",
    "    acc_list = [tab for tab in table_list if acc_keyword in tab and acc_pattern in tab]\n",
    "    acc_df = pd.DataFrame()\n",
    "    for tab in acc_list:\n",
    "        file_path = os.path.join(directory, tab)\n",
    "        df = pd.read_csv(file_path)\n",
    "        acc_df = pd.concat([acc_df, df], axis=0)\n",
    "    # Compute RMSE if the 'MSEdenorm' column is available\n",
    "    if 'MSEdenorm' in acc_df.columns:\n",
    "        acc_df['RMSE'] = np.sqrt(acc_df['MSEdenorm'])\n",
    "    \n",
    "    # Load and combine MI tables\n",
    "    mi_list = [tab for tab in table_list if mi_keyword in tab and mi_pattern in tab]\n",
    "    mi_df = pd.DataFrame()\n",
    "    for tab in mi_list:\n",
    "        file_path = os.path.join(directory, tab)\n",
    "        df = pd.read_csv(file_path)\n",
    "        mi_df = pd.concat([mi_df, df], axis=0)\n",
    "    \n",
    "    return acc_df, mi_df\n",
    "\n",
    "\n",
    "def load_config_models(config_directory, include_keyword='Config', exclude_keyword='Eval', key='Models'):\n",
    "    \"\"\"\n",
    "    Load configuration files from the specified directory and extract model keys.\n",
    "\n",
    "    Parameters:\n",
    "        config_directory (str): Path to the directory containing YAML configuration files.\n",
    "        include_keyword (str): Only consider files that include this keyword.\n",
    "        exclude_keyword (str): Exclude files that contain this keyword.\n",
    "        key (str): The key in the YAML file from which to extract model definitions.\n",
    "\n",
    "    Returns:\n",
    "        model_dict (dict): A dictionary mapping configuration file names (without extension)\n",
    "                           to a list of model keys.\n",
    "    \"\"\"\n",
    "    config_files = [f for f in os.listdir(config_directory)\n",
    "                    if include_keyword in f and exclude_keyword not in f]\n",
    "    model_dict = {}\n",
    "    for config in config_files:\n",
    "        full_path = os.path.join(config_directory, config)\n",
    "        config_data = ReadYaml(full_path)\n",
    "        model_dict[config.split('.')[0]] = list(config_data.get(key, {}).keys())\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main evaluation tables\n",
    "eval_directory = './EvalResults/Tables/'\n",
    "AcctableSet, MItableSet = load_evaluation_tables(\n",
    "    eval_directory,\n",
    "    acc_keyword='Acc',\n",
    "    acc_pattern='Nj1_FC',\n",
    "    mi_keyword='MI',\n",
    "    mi_pattern='Nj1_FC')\n",
    "\n",
    "\n",
    "# Benchmark evaluation tables\n",
    "bench_directory = './Benchmarks/EvalResults/Tables/'\n",
    "BenchAcctableSet, BenchMItableSet = load_evaluation_tables(\n",
    "    bench_directory,\n",
    "    acc_keyword='Acc',\n",
    "    acc_pattern='NjAll',\n",
    "    mi_keyword='MI',\n",
    "    mi_pattern='NjAll')\n",
    "\n",
    "# Define a mapping for metrics to be unified\n",
    "metrics_map = {\n",
    "    '(i) $I(V;\\\\acute{\\\\Theta} \\\\mid X)$': '(ii) $I(V;\\\\acute{\\\\Theta} \\\\mid \\\\acute{Z})$',\n",
    "    '(ii) $I(S;\\\\acute{\\\\Theta} \\\\mid X)$': '(iii) $I(S;\\\\acute{\\\\Theta} \\\\mid \\\\acute{Z})$'}\n",
    "\n",
    "# Create a new column ('UnifiedMetric') while preserving the original 'Metrics'\n",
    "BenchMItableSet['Metrics'] = BenchMItableSet['Metrics'].replace(metrics_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Construct Analysis Table and Perform ISCORE-Based Parameter Selection for Main Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    return np.log1p(np.exp(x))  # numerically stable version of log(1 + exp(x))\n",
    "\n",
    "def load_config_models(config_directory, include_keyword='Config', exclude_keyword='Eval', key='Models'):\n",
    "    \"\"\"\n",
    "    Load configuration files from the specified directory and extract model keys.\n",
    "\n",
    "    Parameters:\n",
    "        config_directory (str): Path to the directory containing YAML configuration files.\n",
    "        include_keyword (str): Only consider files that include this keyword.\n",
    "        exclude_keyword (str): Exclude files that contain this keyword.\n",
    "        key (str): The key in the YAML file from which to extract model definitions.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping configuration file names (without extension)\n",
    "              to a list of model keys.\n",
    "    \"\"\"\n",
    "    config_files = [f for f in os.listdir(config_directory)\n",
    "                    if include_keyword in f and exclude_keyword not in f]\n",
    "    model_dict = {}\n",
    "    for config in config_files:\n",
    "        full_path = os.path.join(config_directory, config)\n",
    "        config_data = ReadYaml(full_path)\n",
    "        model_dict[config.split('.')[0]] = list(config_data.get(key, {}).keys())\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def prepare_analysis_table(mi_df, acc_df, target_models, mi_metrics):\n",
    "    \"\"\"\n",
    "    Prepare the analysis table by merging MI and accuracy data, filtering by target models and metrics,\n",
    "    computing composite score metrics, and parsing model parameters.\n",
    "\n",
    "    Parameters:\n",
    "        mi_df (DataFrame): DataFrame containing MI evaluation results.\n",
    "        acc_df (DataFrame): DataFrame containing accuracy evaluation results.\n",
    "        target_models (list): List of model names to include in the analysis.\n",
    "        mi_metrics (list): List of MI metrics (strings) to retain in the analysis.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The merged and processed analysis table containing performance metrics,\n",
    "                   composite ISCORE, scaling factors, and parsed model parameters.\n",
    "    \"\"\"\n",
    "    # Filter evaluation tables based on the target models\n",
    "    mi_table = mi_df[mi_df['Model'].isin(target_models)].reset_index(drop=True)\n",
    "    acc_table = acc_df[acc_df['Model'].isin(target_models)].reset_index(drop=True)\n",
    "    \n",
    "    # Normalize MAPE and select required columns for accuracy table\n",
    "    if 'MAPEnorm' in acc_table.columns:\n",
    "        acc_table['MAPEnorm'] = acc_table['MAPEnorm'] / 100\n",
    "    acc_table = acc_table[['Model', 'MeanKldRes', 'RMSE']].copy()\n",
    "    acc_table.columns = ['Model', 'FQI', 'RMSE']\n",
    "    \n",
    "    # Process MI table: group by Model and Metrics, average values, then filter and pivot the table\n",
    "    mi_grouped = mi_table.groupby(['Model', 'Metrics']).mean().reset_index()\n",
    "    #mi_filtered = mi_grouped[mi_grouped['Metrics'].isin(mi_metrics)].reset_index(drop=True)\n",
    "    mi_pivot = pd.pivot(mi_grouped, index='Model', columns='Metrics', values='Values').reset_index()\n",
    "    mi_pivot = mi_pivot.fillna(0)\n",
    "    \n",
    "    # Merge MI and accuracy tables\n",
    "    merged_table = pd.merge(mi_pivot, acc_table, on='Model', how='inner').sort_values('Model').reset_index(drop=True)\n",
    "    \n",
    "    # Split the 'Model' string into structural parameters\n",
    "    split_cols = merged_table['Model'].str.split('_', expand=True)\n",
    "    if split_cols.shape[1] == 6:\n",
    "        split_cols.columns = ['Prefix', 'Type', 'Depth', 'LatDim', 'Comp', 'Source']\n",
    "        merged_table = pd.concat([merged_table, split_cols], axis=1)\n",
    "    elif split_cols.shape[1] == 4:\n",
    "        mask = split_cols[3].isna() | (split_cols[3] == 'None')\n",
    "        split_cols.loc[mask, 3] = split_cols.loc[mask, 2]\n",
    "        split_cols.loc[mask, 2] = 0\n",
    "        split_cols.columns = ['Prefix', 'Type', 'LatDim', 'Source']\n",
    "        merged_table = pd.concat([merged_table, split_cols], axis=1)\n",
    "    else:\n",
    "        print(\"Warning: Unexpected model naming format. Check the 'Model' column.\")\n",
    "    \n",
    "    # Compute composite information score (ISCORE)\n",
    "    merged_table['ISCORE'] = softplus(\n",
    "        merged_table['(i) $I(V; \\\\acute{Z} \\\\mid Z)$'] +\n",
    "        merged_table['(iii) $I(S;\\\\acute{\\\\Theta} \\\\mid \\\\acute{Z})$'] -\n",
    "        merged_table['(ii) $I(V;\\\\acute{\\\\Theta} \\\\mid \\\\acute{Z})$']\n",
    "    )\n",
    "    \n",
    "    # Compute scaling based on exponential of FQI and RMSE and then the scaled ISCORE\n",
    "    merged_table['Scaling'] = (np.exp(-merged_table['FQI']) + np.exp(-merged_table['RMSE'])) / 2\n",
    "    merged_table['ISCOREScal'] = merged_table['ISCORE'] * merged_table['Scaling']\n",
    "    \n",
    "    return merged_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Analysis Table and Perform ISCORE-Based Parameter Selection for Main Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration models and combine all model keys across configuration files\n",
    "config_directory = './Config/'\n",
    "TabLists = load_config_models(config_directory)\n",
    "AnalTabList = list(np.concatenate([tabs for key, tabs in TabLists.items()]))\n",
    "\n",
    "# Define ablation models to exclude from final analysis (if needed later)\n",
    "AblationList = [\n",
    "    'FC_ART_1_50_800_Mimic', 'FC_ART_1_50_800_VitalDB',\n",
    "    'SKZ_ART_1_50_800_Mimic', 'SKZ_ART_1_50_800_VitalDB',\n",
    "    'FC_II_1_50_800_Mimic', 'FC_II_1_50_800_VitalDB',\n",
    "    'SKZ_II_1_50_800_Mimic', 'SKZ_II_1_50_800_VitalDB'\n",
    "]\n",
    "\n",
    "# Define MI metrics to be used in the analysis\n",
    "AnalMetricList = [\n",
    "    '(i) $I(V; \\\\acute{Z} \\\\mid Z)$',\n",
    "    '(ii) $I(V;\\\\acute{\\\\Theta} \\\\mid \\\\acute{Z})$',\n",
    "    '(iii) $I(S;\\\\acute{\\\\Theta} \\\\mid \\\\acute{Z})$'\n",
    "]\n",
    "\n",
    "\n",
    "# Prepare the merged analysis table using the function\n",
    "AnalAccMItable = prepare_analysis_table(MItableSet, AcctableSet, AnalTabList, AnalMetricList)\n",
    "\n",
    "# Exclude ablation models from main analysis\n",
    "SenseAccMItable = AnalAccMItable[~AnalAccMItable['Model'].isin(AblationList)]\n",
    "\n",
    "\n",
    "# Parameter search: find optimal Depth, LatDim, Comp per Type based on ISCOREScal\n",
    "ParamSearch = pd.DataFrame()\n",
    "for metric in ['Depth', 'LatDim', 'Comp']:\n",
    "    ResTableGroup = SenseAccMItable.groupby(['Type', metric]).mean(numeric_only=True).reset_index()\n",
    "    Param = ResTableGroup.loc[ResTableGroup.groupby(\"Type\")[\"ISCOREScal\"].idxmax(), [\"Type\", metric, \"ISCOREScal\"]]\n",
    "    Param['Param'] = metric\n",
    "    Param = Param.rename(columns={metric : 'Value'})[['Type','Param', 'Value', 'ISCOREScal']]\n",
    "    ParamSearch = pd.concat([ParamSearch, Param], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Analysis Table (ISCORE-Based) for Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration models and combine all model keys across configuration files\n",
    "Bench_config_directory = './Benchmarks/Config/'\n",
    "BenchTabLists = load_config_models(Bench_config_directory)\n",
    "BenchAnalTabList = list(np.concatenate([tabs for key, tabs in BenchTabLists.items()]))\n",
    "\n",
    "# Prepare the merged analysis table using the function\n",
    "BenchAnalAccMItable = prepare_analysis_table(BenchMItableSet, BenchAcctableSet, BenchAnalTabList, AnalMetricList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert parameter search result into dictionary format:\n",
    "# e.g., ParamDict = {'ART': {'Depth': '1', 'LatDim': '50', 'Comp': '800'}, ...}\n",
    "ParamDict = { t: { row['Param']: row['Value']\n",
    "                    for _, row in ParamSearch[ParamSearch['Type'] == t].iterrows()\n",
    "                 }  for t in ParamSearch['Type'].unique() }\n",
    "\n",
    "\n",
    "BestModelList = pd.DataFrame()\n",
    "# Iterate over sources and types to find best models based on selected parameters\n",
    "for Source in ['Mimic','VitalDB']:\n",
    "    SelDataset = SenseAccMItable[SenseAccMItable['Source'] == Source]\n",
    "    for Type, Value in ParamDict.items():\n",
    "        SelModels = SenseAccMItable[(SenseAccMItable['Type'] == Type) & \n",
    "                        (SenseAccMItable['Depth'] == Value['Depth']) & \n",
    "                        (SenseAccMItable['LatDim'] == Value['LatDim']) & \n",
    "                        (SenseAccMItable['Comp'] == Value['Comp']) &\n",
    "                        (SenseAccMItable['Source'] == Source)]\n",
    "        BestModelList = pd.concat([BestModelList, SelModels]) \n",
    "\n",
    "# Build the comparison table including both ablation models and selected best models\n",
    "AblaAccMItable = AnalAccMItable[AnalAccMItable['Model'].isin( AblationList + BestModelList['Model'].tolist())]\n",
    "\n",
    "# Build the comparison table including both benchmark models and selected best models\n",
    "MainCompList = ['SKZFC_ART_1_30_800_Mimic',  'SKZFC_II_1_30_800_Mimic', 'SKZFC_ART_1_30_800_VitalDB', 'SKZFC_II_1_30_800_VitalDB']\n",
    "SelModelComp = AnalAccMItable[AnalAccMItable['Model'].isin( MainCompList)][BenchAnalAccMItable.columns]\n",
    "BenchAnalAccMItable = pd.concat([BenchAnalAccMItable, SelModelComp]).copy()\n",
    "\n",
    "\n",
    "# BenchAnalAccMItable[(BenchAnalAccMItable['Type'] =='II') & (BenchAnalAccMItable['Source'] =='Mimic')].sort_values('ISCOREScal')\n",
    "# 1. ART & VitalDB: SKZFC_ART_1_30_800_VitalDB, VDWave_ART_VitalDB, TCVAE_ART_30_VitalDB\n",
    "# 2. ART & Mimic: SKZFC_ART_1_30_800_Mimic, VDWave_ART_Mimic, TCVAE_ART_30_Mimic\n",
    "# 3. II & VitalDB: SKZFC_II_1_30_800_VitalDB, VDWave_II_VitalDB, TCVAE_II_30_VitalDB\n",
    "# 4. II & Mimic: SKZFC_II_1_30_800_Mimic, VDWave_II_Mimic, TCVAE_II_30_Mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>(i) $I(V; \\acute{Z} \\mid Z)$</th>\n",
       "      <th>(ii) $I(V;\\acute{\\Theta} \\mid \\acute{Z})$</th>\n",
       "      <th>(iii) $I(S;\\acute{\\Theta} \\mid \\acute{Z})$</th>\n",
       "      <th>FQI</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>LatDim</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Source</th>\n",
       "      <th>ISCORE</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>ISCOREScal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SKZFC_ART_1_50_800_Mimic</td>\n",
       "      <td>3.517190</td>\n",
       "      <td>0.057243</td>\n",
       "      <td>0.789660</td>\n",
       "      <td>0.085957</td>\n",
       "      <td>3.673249</td>\n",
       "      <td>SKZFC</td>\n",
       "      <td>ART</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>800</td>\n",
       "      <td>Mimic</td>\n",
       "      <td>4.263776</td>\n",
       "      <td>0.471514</td>\n",
       "      <td>2.010429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SKZFC_II_1_50_800_Mimic</td>\n",
       "      <td>2.767104</td>\n",
       "      <td>0.161047</td>\n",
       "      <td>0.765604</td>\n",
       "      <td>0.223932</td>\n",
       "      <td>0.380783</td>\n",
       "      <td>SKZFC</td>\n",
       "      <td>II</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>800</td>\n",
       "      <td>Mimic</td>\n",
       "      <td>3.405418</td>\n",
       "      <td>0.741348</td>\n",
       "      <td>2.524598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SKZFC_ART_1_50_800_VitalDB</td>\n",
       "      <td>4.272571</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>1.000776</td>\n",
       "      <td>0.042677</td>\n",
       "      <td>4.600318</td>\n",
       "      <td>SKZFC</td>\n",
       "      <td>ART</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>800</td>\n",
       "      <td>VitalDB</td>\n",
       "      <td>5.259697</td>\n",
       "      <td>0.484135</td>\n",
       "      <td>2.546401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SKZFC_II_1_50_800_VitalDB</td>\n",
       "      <td>2.004492</td>\n",
       "      <td>0.101633</td>\n",
       "      <td>0.691140</td>\n",
       "      <td>0.169844</td>\n",
       "      <td>0.049781</td>\n",
       "      <td>SKZFC</td>\n",
       "      <td>II</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>800</td>\n",
       "      <td>VitalDB</td>\n",
       "      <td>2.666059</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>2.393101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  (i) $I(V; \\acute{Z} \\mid Z)$  \\\n",
       "8     SKZFC_ART_1_50_800_Mimic                      3.517190   \n",
       "20     SKZFC_II_1_50_800_Mimic                      2.767104   \n",
       "9   SKZFC_ART_1_50_800_VitalDB                      4.272571   \n",
       "21   SKZFC_II_1_50_800_VitalDB                      2.004492   \n",
       "\n",
       "    (ii) $I(V;\\acute{\\Theta} \\mid \\acute{Z})$  \\\n",
       "8                                    0.057243   \n",
       "20                                   0.161047   \n",
       "9                                    0.018860   \n",
       "21                                   0.101633   \n",
       "\n",
       "    (iii) $I(S;\\acute{\\Theta} \\mid \\acute{Z})$       FQI      RMSE Prefix  \\\n",
       "8                                     0.789660  0.085957  3.673249  SKZFC   \n",
       "20                                    0.765604  0.223932  0.380783  SKZFC   \n",
       "9                                     1.000776  0.042677  4.600318  SKZFC   \n",
       "21                                    0.691140  0.169844  0.049781  SKZFC   \n",
       "\n",
       "   Type Depth LatDim Comp   Source    ISCORE   Scaling  ISCOREScal  \n",
       "8   ART     1     50  800    Mimic  4.263776  0.471514    2.010429  \n",
       "20   II     1     50  800    Mimic  3.405418  0.741348    2.524598  \n",
       "9   ART     1     50  800  VitalDB  5.259697  0.484135    2.546401  \n",
       "21   II     1     50  800  VitalDB  2.666059  0.897617    2.393101  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BestModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation Summary Tables to 'EvalResults/SummaryTables/' Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./EvalResults/SummaryTables/AnalAccMItable.csv\n",
      "Saved: ./EvalResults/SummaryTables/SenseAccMItable.csv\n",
      "Saved: ./EvalResults/SummaryTables/BenchAnalAccMItable.csv\n",
      "Saved: ./EvalResults/SummaryTables/AblaAccMItable.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory\n",
    "output_dir = './EvalResults/SummaryTables/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define table name to DataFrame mapping\n",
    "tables_to_save = {\n",
    "    'AnalAccMItable.csv': AnalAccMItable,\n",
    "    'SenseAccMItable.csv': SenseAccMItable,\n",
    "    'BenchAnalAccMItable.csv': BenchAnalAccMItable,\n",
    "    'AblaAccMItable.csv': AblaAccMItable,\n",
    "}\n",
    "\n",
    "# Save each DataFrame to the specified directory\n",
    "for filename, df in tables_to_save.items():\n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
